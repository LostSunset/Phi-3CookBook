# Phi-3-Vision-128K-Instruct 项目概述

## 模型

Phi-3-Vision-128K-Instruct 是该项目的核心，它是一个轻量级的、最先进的多模态模型，属于 Phi-3 模型家族，支持最长 128,000 个 tokens 的上下文长度。该模型在多样化的数据集上进行训练，包括合成数据和经过精心筛选的公开网站数据，重点是高质量、需要推理的内容。训练过程包括监督微调和直接偏好优化，以确保准确遵循指令，并采取了强有力的安全措施。

## 创建样本数据至关重要的几个原因：

1. **测试**：样本数据允许你在各种场景下测试应用程序，而不会影响真实数据。这在开发和预发布阶段尤为重要。

2. **性能调优**：通过模拟真实数据规模和复杂度的样本数据，可以识别性能瓶颈并相应地优化应用程序。

3. **原型设计**：样本数据可以用于创建原型和模型，有助于理解用户需求并获取反馈。

4. **数据分析**：在数据科学中，样本数据常用于探索性数据分析、模型训练和算法测试。

5. **安全性**：在开发和测试环境中使用样本数据可以帮助防止敏感真实数据的意外泄露。

6. **学习**：如果你在学习新技术或工具，使用样本数据可以提供一个实际应用所学知识的途径。

记住，样本数据的质量会显著影响这些活动。它在结构和多样性上应该尽可能接近真实数据。

### 样本数据创建
[生成数据集脚本](./CreatingSampleData.md)

## 数据集

一个好的样本数据集示例是 [DBQ/Burberry.Product.prices.United.States dataset](https://huggingface.co/datasets/DBQ/Burberry.Product.prices.United.States)（在 Huggingface 上可用）。该样本数据集包含 Burberry 产品及其元数据，包括产品类别、价格和标题，共有 3,040 行，每行代表一个独特的产品。这个数据集让我们测试模型理解和解释视觉数据的能力，生成捕捉复杂视觉细节和品牌特征的描述性文本。

**注意：** 你可以使用任何包含图像的数据集。

## 复杂推理

模型需要在只有图像的情况下对价格和命名进行推理。这要求模型不仅识别视觉特征，还要理解它们在产品价值和品牌方面的意义。通过从图像中合成准确的文本描述，该项目展示了将视觉数据集成以增强模型在现实应用中性能和多功能性的潜力。

## Phi-3 Vision 架构

该模型架构是 Phi-3 的多模态版本。它处理文本和图像数据，将这些输入整合成一个统一的序列以进行全面的理解和生成任务。模型为文本和图像使用了不同的嵌入层。文本 tokens 被转换为密集向量，而图像则通过 CLIP 视觉模型处理以提取特征嵌入。这些图像嵌入随后被投射以匹配文本嵌入的维度，确保它们可以无缝集成。

## 文本和图像嵌入的整合

文本序列中的特殊 tokens 指示图像嵌入应插入的位置。在处理过程中，这些特殊 tokens 被相应的图像嵌入替换，使模型能够将文本和图像作为一个单一序列处理。我们的数据集的提示使用特殊的 <|image|> token 格式如下：

```python
text = f"<|user|>\n<|image_1|>What is shown in this image?<|end|><|assistant|>\nProduct: {row['title']}, Category: {row['category3_code']}, Full Price: {row['full_price']}<|end|>"
```

## 示例代码
- [Phi-3-Vision 训练脚本](../../../../code/04.Finetuning/Phi-3-vision-Trainingscript.py)
- [Weights and Bias 示例演练](https://wandb.ai/byyoung3/mlnews3/reports/How-to-fine-tune-Phi-3-vision-on-a-custom-dataset--Vmlldzo4MTEzMTg3)

免责声明：此翻译由AI模型从原文翻译而来，可能不够完美。请审查输出内容并进行必要的修改。