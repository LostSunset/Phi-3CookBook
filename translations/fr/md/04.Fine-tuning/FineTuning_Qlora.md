**Ajustement fin de Phi-3 avec QLoRA**

Ajustement fin du modèle de langage Phi-3 Mini de Microsoft en utilisant [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora).

QLoRA aidera à améliorer la compréhension conversationnelle et la génération de réponses.

Pour charger les modèles en 4 bits avec transformers et bitsandbytes, vous devez installer accelerate et transformers à partir de la source et vous assurer d'avoir la dernière version de la bibliothèque bitsandbytes.

**Exemples**
- [En savoir plus avec cet exemple de notebook](../../../../code/04.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Exemple de script d'ajustement fin en Python](../../../../code/04.Finetuning/FineTrainingScript.py)
- [Exemple d'ajustement fin sur Hugging Face Hub avec LORA](../../../../code/04.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Exemple d'ajustement fin sur Hugging Face Hub avec QLORA](../../../../code/04.Finetuning/Phi-3-finetune-qlora-python.ipynb)

        **Avertissement** : 
        Ce document a été traduit en utilisant des services de traduction basés sur l'IA. Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit être considéré comme la source faisant autorité. Pour des informations critiques, une traduction humaine professionnelle est recommandée. Nous ne sommes pas responsables des malentendus ou des interprétations erronées résultant de l'utilisation de cette traduction.