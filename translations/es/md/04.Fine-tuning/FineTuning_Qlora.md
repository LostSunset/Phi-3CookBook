**Ajuste fino de Phi-3 con QLoRA**

Ajuste fino del modelo de lenguaje Phi-3 Mini de Microsoft utilizando [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora).

QLoRA ayudará a mejorar la comprensión conversacional y la generación de respuestas.

Para cargar modelos en 4 bits con transformers y bitsandbytes, debes instalar accelerate y transformers desde la fuente y asegurarte de tener la última versión de la biblioteca bitsandbytes.

**Ejemplos**
- [Aprende más con este cuaderno de ejemplo](../../../../code/04.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Ejemplo de ajuste fino en Python](../../../../code/04.Finetuning/FineTrainingScript.py)
- [Ejemplo de ajuste fino en Hugging Face Hub con LORA](../../../../code/04.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Ejemplo de ajuste fino en Hugging Face Hub con QLORA](../../../../code/04.Finetuning/Phi-3-finetune-qlora-python.ipynb)

Aviso legal: La traducción fue realizada a partir del original por un modelo de IA y puede no ser perfecta. 
Por favor, revise el resultado y haga las correcciones necesarias.