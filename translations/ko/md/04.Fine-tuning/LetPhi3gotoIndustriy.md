# **Phi-3을 업계 전문가로 만들기**

Phi-3 모델을 산업에 적용하려면 산업 비즈니스 데이터를 Phi-3 모델에 추가해야 합니다. 이를 위한 두 가지 옵션이 있습니다. 첫 번째는 RAG(Retrieval Augmented Generation)이고 두 번째는 Fine Tuning입니다.

## **RAG vs Fine-Tuning**

### **Retrieval Augmented Generation**

RAG는 데이터 검색 + 텍스트 생성입니다. 기업의 구조화된 데이터와 비구조화된 데이터는 벡터 데이터베이스에 저장됩니다. 관련 내용을 검색할 때, 관련 요약과 내용을 찾아 컨텍스트를 형성하고 LLM/SLM의 텍스트 완성 기능을 결합하여 콘텐츠를 생성합니다.

### **Fine-tuning**

Fine-tuning은 특정 모델의 개선을 기반으로 합니다. 모델 알고리즘에서 시작할 필요는 없지만 데이터를 지속적으로 축적해야 합니다. 산업 애플리케이션에서 더 정확한 용어와 언어 표현이 필요하다면 Fine-tuning이 더 나은 선택이 될 것입니다. 하지만 데이터가 자주 변경되는 경우 Fine-tuning은 복잡해질 수 있습니다.

### **선택 방법**

1. 답변에 외부 데이터 도입이 필요한 경우 RAG가 최선의 선택입니다.

2. 안정적이고 정확한 산업 지식을 출력해야 하는 경우 Fine-tuning이 좋은 선택입니다. RAG는 관련 콘텐츠를 우선적으로 가져오지만, 항상 전문적인 뉘앙스를 완벽하게 잡아내지는 못할 수 있습니다.

3. Fine-tuning은 고품질 데이터 세트가 필요하며, 작은 범위의 데이터만으로는 큰 차이를 만들지 못할 것입니다. RAG는 더 유연합니다.

4. Fine-tuning은 블랙박스, 즉 불가사의로 내부 메커니즘을 이해하기 어렵습니다. 하지만 RAG는 데이터의 출처를 쉽게 찾을 수 있어 환각이나 콘텐츠 오류를 효과적으로 조정하고 더 나은 투명성을 제공합니다.

### **시나리오**

1. 특정 전문 용어와 표현이 필요한 수직 산업에서는 ***Fine-tuning***이 최선의 선택입니다.

2. 다양한 지식 포인트의 합성을 포함하는 QA 시스템에서는 ***RAG***가 최선의 선택입니다.

3. 자동화된 비즈니스 흐름의 결합에서는 ***RAG + Fine-tuning***이 최선의 선택입니다.

## **RAG 사용 방법**

![rag](../../../../translated_images/RAG.099c3f3bc644ff2d8bb61d2fbc20a532958c6a1e4d1cb65a84edeb4ffe618bbb.ko.png)

벡터 데이터베이스는 수학적 형태로 저장된 데이터 모음입니다. 벡터 데이터베이스는 머신 러닝 모델이 이전 입력을 기억하기 쉽게 만들어, 검색, 추천 및 텍스트 생성과 같은 사용 사례를 지원하는 데 머신 러닝을 사용할 수 있게 합니다. 데이터는 정확한 일치가 아닌 유사성 메트릭을 기반으로 식별될 수 있어 컴퓨터 모델이 데이터의 맥락을 이해할 수 있게 합니다.

벡터 데이터베이스는 RAG를 실현하는 데 중요한 역할을 합니다. 우리는 text-embedding-3, jina-ai-embedding 등과 같은 벡터 모델을 통해 데이터를 벡터 저장소로 변환할 수 있습니다.

RAG 애플리케이션 만들기에 대한 자세한 내용은 [https://github.com/microsoft/Phi-3CookBook](https://github.com/microsoft/Phi-3CookBook?WT.mc_id=aiml-138114-kinfeylo)에서 확인하세요.

## **Fine-tuning 사용 방법**

Fine-tuning에서 일반적으로 사용되는 알고리즘은 Lora와 QLora입니다. 어떻게 선택할까요?
- [이 샘플 노트북에서 더 알아보기](../../../../code/04.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Python FineTuning 샘플 예제](../../../../code/04.Finetuning/FineTrainingScript.py)

### **Lora와 QLora**

![lora](../../../../translated_images/qlora.ea4ce73918753819dc9e9cf1524ac40faa555d6b21168b667064be93c3913bbe.ko.png)

LoRA(Low-Rank Adaptation)와 QLoRA(Quantized Low-Rank Adaptation)는 모두 Parameter Efficient Fine Tuning(PEFT)을 사용하여 대형 언어 모델(LLM)을 미세 조정하는 기술입니다. PEFT 기술은 전통적인 방법보다 모델을 더 효율적으로 훈련하도록 설계되었습니다. LoRA는 가중치 업데이트 행렬에 저순위 근사를 적용하여 메모리 사용량을 줄이는 독립형 미세 조정 기술입니다. 빠른 훈련 시간을 제공하며 전통적인 미세 조정 방법에 가까운 성능을 유지합니다.

QLoRA는 LoRA의 확장 버전으로, 양자화 기술을 통합하여 메모리 사용량을 더욱 줄입니다. QLoRA는 사전 훈련된 LLM의 가중치 파라미터의 정밀도를 4비트 정밀도로 양자화하여 LoRA보다 더 메모리 효율적입니다. 그러나 추가적인 양자화 및 디양자화 단계로 인해 QLoRA 훈련은 LoRA 훈련보다 약 30% 느립니다.

QLoRA는 양자화 오류를 수정하기 위해 LoRA를 보조 도구로 사용합니다. QLoRA는 비교적 작은, 쉽게 구할 수 있는 GPU로 수십억 개의 파라미터를 가진 거대한 모델을 미세 조정할 수 있게 합니다. 예를 들어, QLoRA는 36개의 GPU가 필요한 70B 파라미터 모델을 단 2개의 GPU로 미세 조정할 수 있습니다.

**면책 조항**:
이 문서는 기계 기반 AI 번역 서비스를 사용하여 번역되었습니다. 우리는 정확성을 위해 노력하지만 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서는 해당 언어로 작성된 것이 권위 있는 출처로 간주되어야 합니다. 중요한 정보의 경우 전문적인 인간 번역을 권장합니다. 이 번역의 사용으로 인해 발생하는 오해나 오역에 대해 우리는 책임을 지지 않습니다.