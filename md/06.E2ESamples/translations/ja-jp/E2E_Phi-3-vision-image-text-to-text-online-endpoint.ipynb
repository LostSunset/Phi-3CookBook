{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (ビジュアル) チャット補完推論のオンラインエンドポイントの使用\n",
    "\n",
    "このサンプルでは、`Phi-3-vision-128k-instruct` をオンラインエンドポイントにデプロイして推論を行う方法を示します。\n",
    "\n",
    "### 概要\n",
    "* 前提条件の設定\n",
    "* デプロイするモデルの選択\n",
    "* 推論用データのダウンロードと準備\n",
    "* モデルのデプロイによるリアルタイム推論\n",
    "* エンドポイントのテスト\n",
    "* Azure OpenAI スタイルのペイロードを使用したエンドポイントのテスト\n",
    "* リソースのクリーンアップ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 前提条件の設定\n",
    "* 依存関係のインストール\n",
    "* AzureML ワークスペースに接続します。詳細は [SDK 認証の設定](https://learn.microsoft.com/azure/machine-learning/how-to-setup-authentication?tabs=sdk) を参照してください。以下の `<WORKSPACE_NAME>`、`<RESOURCE_GROUP>`、および `<SUBSCRIPTION_ID>` を置き換えます。\n",
    "* `azureml` システムレジストリに接続します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポートします\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "\n",
    "try:\n",
    "    # デフォルトの Azure 資格情報を取得しようとします\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # デフォルトの資格情報が利用できない場合、インタラクティブブラウザ資格情報を使用します\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    # 提供された資格情報を使用して MLClient を作成しようとします\n",
    "    workspace_ml_client = MLClient.from_config(credential)\n",
    "    subscription_id = workspace_ml_client.subscription_id\n",
    "    resource_group = workspace_ml_client.resource_group_name\n",
    "    workspace_name = workspace_ml_client.workspace_name\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # MLClient の作成に失敗した場合、AML ワークスペースの詳細を手動で入力します\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace_name = \"<WORKSPACE_NAME>\"\n",
    "\n",
    "# 提供された資格情報とワークスペースの詳細を使用して MLClient インスタンスを作成します\n",
    "workspace_ml_client = MLClient(\n",
    "    credential, subscription_id, resource_group, workspace_name\n",
    ")\n",
    "\n",
    "# モデル、ファインチューニングパイプライン、および環境は AzureML システムレジストリ \"azureml\" にあります\n",
    "registry_ml_client = MLClient(credential, registry_name=\"azureml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. モデルをオンラインエンドポイントにデプロイする\n",
    "オンラインエンドポイントは、モデルを使用する必要があるアプリケーションと統合するために使用できる耐久性のある REST API を提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このコードは、指定された名前のモデルがレジストリに存在するかどうかを確認します。\n",
    "# モデルが存在する場合、モデルの最初のバージョンを取得し、その詳細を表示します。\n",
    "# モデルが存在しない場合、モデルが見つからなかったことを示すメッセージを表示します。\n",
    "\n",
    "# model_name: レジストリで確認するモデルの名前\n",
    "model_name = \"Phi-3-vision-128k-instruct\"\n",
    "\n",
    "# 指定されたモデル名のバージョンリストを取得します\n",
    "version_list = list(registry_ml_client.models.list(model_name))\n",
    "\n",
    "# レジストリにモデルのバージョンが存在するかどうかを確認します\n",
    "if len(version_list) == 0:\n",
    "    print(\"レジストリにモデルが見つかりません\")\n",
    "else:\n",
    "    # モデルの最初のバージョンを取得します\n",
    "    model_version = version_list[0].version\n",
    "    foundation_model = registry_ml_client.models.get(model_name, model_version)\n",
    "    \n",
    "    # モデルの詳細を表示します\n",
    "    print(\n",
    "        \"\\n\\n推論に使用するモデル名: {0}, バージョン: {1}, ID: {2}\".format(\n",
    "            foundation_model.name, foundation_model.version, foundation_model.id\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポートします\n",
    "import time\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
    "\n",
    "# オンラインエンドポイントを作成します - エンドポイント名はリージョン内で一意である必要があるため、タイムスタンプを使用して一意のエンドポイント名を作成します\n",
    "timestamp = int(time.time())\n",
    "online_endpoint_name = model_name[:13] + str(timestamp)\n",
    "print(f\"名前: {online_endpoint_name} のオンラインエンドポイントを作成します\")\n",
    "\n",
    "# オンラインエンドポイントを作成します\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=f\"{foundation_model.name} のオンラインエンドポイント、ビジュアルチャット補完タスク用\",\n",
    "    auth_mode=\"key\",\n",
    ")\n",
    "workspace_ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このコードは、オンラインエンドポイントのデプロイメントを作成します。\n",
    "# デプロイメント名、エンドポイント名、モデル、インスタンスタイプ、インスタンス数、およびリクエスト設定を設定します。\n",
    "# また、ライブネスプローブとレディネスプローブの設定も行います。\n",
    "# 最後に、エンドポイントのトラフィック分布を更新します。\n",
    "\n",
    "from azure.ai.ml.entities import OnlineRequestSettings, ProbeSettings\n",
    "\n",
    "# デプロイメントを作成します\n",
    "deployment_name = \"phi-3-vision\"\n",
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=deployment_name,\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=foundation_model.id,\n",
    "    instance_type=\"Standard_NC48ads_A100_v4\",\n",
    "    instance_count=1,\n",
    "    request_settings=OnlineRequestSettings(\n",
    "        request_timeout_ms=180000,\n",
    "        max_queue_wait_ms=500,\n",
    "    ),\n",
    "    liveness_probe=ProbeSettings(\n",
    "        failure_threshold=49,\n",
    "        success_threshold=1,\n",
    "        timeout=299,\n",
    "        period=180,\n",
    "        initial_delay=180,\n",
    "    ),\n",
    "    readiness_probe=ProbeSettings(\n",
    "        failure_threshold=10,\n",
    "        success_threshold=1,\n",
    "        timeout=10,\n",
    "        period=10,\n",
    "        initial_delay=10,\n",
    "    ),\n",
    ")\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
    "endpoint.traffic = {deployment_name: 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. サンプルデータを使用してエンドポイントをテストする\n",
    "\n",
    "以下に作成する json を使用して、モデルにサンプルリクエストを送信します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポートします\n",
    "import json\n",
    "import os\n",
    "\n",
    "# テスト JSON ペイロードを定義します\n",
    "test_json = {\n",
    "    \"input_data\": {\n",
    "        \"input_string\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": \"https://www.ilankelman.org/stopsigns/australia.jpg\"\n",
    "                        },\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"この画像に何が表示されていますか？非常に詳細かつ具体的に説明してください。\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        \"parameters\": {\"temperature\": 0.7, \"max_new_tokens\": 2048},\n",
    "    }\n",
    "}\n",
    "\n",
    "# JSON オブジェクトをファイルに保存します\n",
    "sample_score_file_path = os.path.join(\".\", \"sample_chat_completions_score.json\")\n",
    "with open(sample_score_file_path, \"w\") as f:\n",
    "    json.dump(test_json, f, indent=4)\n",
    "\n",
    "# 入力ペイロードを表示します\n",
    "print(\"入力ペイロード:\\n\")\n",
    "print(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポートします\n",
    "import pandas as pd\n",
    "\n",
    "# azureml エンドポイントの invoke メソッドを使用して、sample_chat_completions_score.json ファイルをオンラインエンドポイントでスコアリングします\n",
    "response = workspace_ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=deployment_name,\n",
    "    request_file=sample_score_file_path,\n",
    ")\n",
    "print(\"生の JSON 応答: \\n\", response, \"\\n\")\n",
    "\n",
    "# JSON 文字列を解析します\n",
    "json_data = json.loads(response)\n",
    "\n",
    "# 解析された JSON を DataFrame に変換します\n",
    "response_df = pd.DataFrame([json_data])\n",
    "print(\"生成されたテキスト:\\n\", response_df[\"output\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Azure OpenAI スタイルのペイロードを使用してエンドポイントをテストする\n",
    "\n",
    "Azure OpenAI スタイルのペイロードを使用して、モデルにサンプルリクエストを送信します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このコードは、Azure OpenAI スタイルのペイロードを使用してオンラインエンドポイントをテストするための JSON ペイロードを定義します。\n",
    "# これには、モデル名、ユーザーロールとコンテンツ（画像 URL とテキスト）を含むメッセージのリスト、\n",
    "# 温度、および max_new_tokens が含まれます。\n",
    "\n",
    "aoai_test_json = {\n",
    "    \"model\": foundation_model.name,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://www.ilankelman.org/stopsigns/australia.jpg\"\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"この画像に何が表示されていますか？非常に詳細かつ具体的に説明してください。\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_new_tokens\": 2048,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スコアリング URI を取得します\n",
    "scoring_uri = workspace_ml_client.online_endpoints.get(\n",
    "    name=online_endpoint_name\n",
    ").scoring_uri\n",
    "# AOAI 用にスコアリング URI を更新します\n",
    "aoai_format_scoring_uri = scoring_uri.replace(\"/score\", \"/v1/chat/completions\")\n",
    "\n",
    "# データプレーン操作のキーを取得します\n",
    "data_plane_token = workspace_ml_client.online_endpoints.get_keys(\n",
    "    name=online_endpoint_name\n",
    ").primary_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "# リクエストを準備します\n",
    "body = str.encode(json.dumps(aoai_test_json))\n",
    "url = aoai_format_scoring_uri\n",
    "api_key = data_plane_token\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": (\"Bearer \" + api_key)}\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "# リクエストを送信し、応答を取得します\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "    result = response.read().decode(\"utf-8\")\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"リクエストがステータスコード: \" + str(error.code) + \" で失敗しました\")\n",
    "    # ヘッダーを表示します - これにはリクエスト ID とタイムスタンプが含まれており、失敗のデバッグに役立ちます\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", \"ignore\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. オンラインエンドポイントを削除する\n",
    "オンラインエンドポイントを削除することを忘れないでください。そうしないと、エンドポイントが使用する計算リソースの料金が発生し続けます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワークスペースを削除します\n",
    "workspace_ml_client.online_endpoints.begin_delete(name=online_endpoint_name).wait()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
