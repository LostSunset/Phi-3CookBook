# Phi-3モデルのAI安全性

Phiファミリーのモデルは、[Microsoftの責任あるAIの原則](https://www.microsoft.com/ai/responsible-ai)に基づいて開発されています。

## ベストプラクティス

他のモデルと同様に、Phiファミリーのモデルも不公平、不確実、または攻撃的な行動をとる可能性があります。

SLMおよびLLMの制限行動には、次のようなものがあります。

- **サービスの質:** Phiモデルは主に英語のテキストで訓練されています。英語以外の言語はパフォーマンスが低下し、訓練データに代表される英語のバリエーションが少ない場合、標準的なアメリカ英語よりもパフォーマンスが低下する可能性があります。
- **ハームの表現とステレオタイプの強化:** これらのモデルは、特定の人々のグループを過剰または過小に表現し、一部のグループの表現を消去したり、侮辱的または否定的なステレオタイプを強化したりする可能性があります。安全な後処理を行っても、異なるグループの代表性のレベルの違いや、現実のパターンや社会的偏見を反映した訓練データ内の否定的なステレオタイプの例の普及により、これらの制限が依然として存在する可能性があります。
- **不適切または攻撃的なコンテンツ:** これらのモデルは、他の種類の不適切または攻撃的なコンテンツを生成する可能性があり、特定の使用ケースに対する追加の緩和策がない場合、敏感なコンテキストでの展開には不適切です。
情報の信頼性: 言語モデルは、無意味なコンテンツを生成したり、合理的に聞こえるが不正確または古いコンテンツを捏造したりすることがあります。
- **コードの範囲の制限:** Phi-3の訓練データの大部分はPythonに基づいており、「typing、math、random、collections、datetime、itertools」などの一般的なパッケージを使用しています。モデルが他のパッケージや他の言語のスクリプトを使用するPythonスクリプトを生成する場合、すべてのAPIの使用を手動で確認することを強くお勧めします。

開発者は、責任あるAIのベストプラクティスを適用し、特定の使用ケースが関連する法律や規制（例：プライバシー、貿易など）に準拠していることを確認する責任があります。

LLMおよびSLMを使用する際に考慮すべき重要な領域には次のものがあります。

- **配分:** モデルは、法的地位やリソースまたは生活機会の配分（例：住宅、雇用、信用など）に重大な影響を与える可能性のあるシナリオには、さらなる評価と追加のデバイアス技術がない限り適していない場合があります。
- **高リスクシナリオ:** 開発者は、不公平、不確実、または攻撃的な出力が非常に高価または害を引き起こす可能性のある高リスクシナリオでモデルを使用する適合性を評価する必要があります。これには、正確性と信頼性が重要な敏感または専門的な領域でのアドバイスの提供が含まれます（例：法律または健康アドバイス）。展開コンテキストに応じて、アプリケーションレベルで追加の保護策を実装する必要があります。
- **誤情報:** モデルは不正確な情報を生成する可能性があります。開発者は透明性のベストプラクティスに従い、エンドユーザーにAIシステムと対話していることを通知する必要があります。アプリケーションレベルでは、開発者はフィードバックメカニズムとパイプラインを構築し、特定の使用ケースに基づいたコンテキスト情報に基づいて応答を行うことができます。この技術は、リトリーバル強化生成（RAG）として知られています。
- **有害なコンテンツの生成:** 開発者は、出力のコンテキストを評価し、使用ケースに適した利用可能な安全分類器またはカスタムソリューションを使用する必要があります。
- **悪用:** 詐欺、スパム、マルウェアの生成などの他の形式の悪用が可能であり、開発者はアプリケーションが適用される法律や規制に違反しないことを確認する必要があります。

### 微調整とAIコンテンツの安全性

モデルを微調整した後、[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview)の対策を活用して、モデルが生成するコンテンツを監視し、潜在的なリスク、脅威、および品質の問題を特定してブロックすることを強くお勧めします。

![Phi3AISafety](../../imgs/01/phi3aisafety.png)

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview)は、テキストおよび画像コンテンツをサポートしています。クラウド、オフラインコンテナ、およびエッジ/組み込みデバイスに展開できます。

## Azure AI Content Safetyの概要

Azure AI Content Safetyは、すべてのビジネスに適した万能のソリューションではありません。ビジネスの特定のポリシーに合わせてカスタマイズできます。さらに、その多言語モデルにより、複数の言語を同時に理解することができます。

![AIContentSafety](../../imgs/01/AIcontentsafety.png)

- **Azure AI Content Safety**
- **Microsoft Developer**
- **5本のビデオ**

Azure AI Content Safetyサービスは、アプリケーションおよびサービス内の有害なユーザー生成およびAI生成コンテンツを検出します。テキストおよび画像APIが含まれており、有害または不適切な素材を検出することができます。

[AI Content Safety Playlist](https://www.youtube.com/playlist?list=PLlrxD0HtieHjaQ9bJjyp1T7FeCbmVcPkQ)
