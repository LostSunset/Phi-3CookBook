# ラボ 2 - Apple SiliconでPhi-3-miniのPrompt flowを実行する

## Prompt flowとは

Prompt flowは、LLM（大規模言語モデル）ベースのAIアプリケーションのアイデアからプロトタイプ、テスト、評価、プロダクションデプロイメント、監視までのエンドツーエンドの開発サイクルを簡素化するための開発ツールセットです。これにより、プロンプトエンジニアリングが大幅に簡素化され、生産品質のLLMアプリケーションを構築することができます。

Prompt flowを使用すると、次のことが可能になります：

- LLM、プロンプト、Pythonコード、およびその他のツールをリンクする実行可能なワークフローを作成します。
- 特にLLMとの対話において、ワークフローを簡単にデバッグおよび反復します。
- ワークフローを評価し、より大きなデータセットを使用して品質とパフォーマンスの指標を計算します。
- ワークフローの品質を確保するために、テストと評価をCI/CDシステムに統合します。
- ワークフローを選択したサービスプラットフォームにデプロイするか、アプリケーションコードベースに簡単に統合します。
- （オプションですが強く推奨）Azure AIのPrompt flowクラウドバージョンを利用してチームと協力します。

## Apple Silicon上でコード生成ワークフローを構築する

***注意***：環境のインストールがまだ完了していない場合は、[ラボ 0 - インストール](./01.Installations.md)にアクセスしてください。

1. Visual Studio CodeでPrompt flow拡張機能を開き、空のワークフロープロジェクトを作成します。

![create](../../../../../../../imgs/07/01/pf_create.png)

2. 入力および出力パラメータを追加し、Pythonコードを新しいワークフローとして追加します。

![flow](../../../../../../../imgs/07/01/pf_flow.png)

次の構造（flow.dag.yaml）を参考にしてワークフローを構築できます。

```yaml
inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}
```

3. phi-3-miniの量子化

SLMをローカルデバイスでより良く実行するために、通常、モデルを量子化します（INT4、FP16、FP32）。

```bash
python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct
```

**注意:** デフォルトのフォルダはmlx_modelです。

4. `Chat_With_Phi3.py`にコードを追加します。

```python
from promptflow import tool
from mlx_lm import load, generate

# 入力部分はツール関数のパラメータに基づいて変更されます。コードを保存した後、
# パラメータと戻り値に型を追加することで、システムが正しい型を表示するのに役立ちます。
# 必要に応じて関数名/シグネチャを更新してください。
@tool
def my_python_tool(prompt: str) -> str:
    model_id = './mlx_model_phi3_mini'
    model, tokenizer = load(model_id)
    # <|user|>\nWrite python code for Fibonacci serie. Please use markdown as output<|end|>\n<|assistant|>
    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)
    return response
```

4. ワークフローをデバッグまたは実行して、生成されたコードが正しいかどうかを確認できます。

![RUN](../../../../../../../imgs/07/01/pf_run.png)

5. ターミナルでワークフローを開発APIとして実行します。

```
pf flow serve --source ./ --port 8080 --host localhost   
```

Postman / Thunder Clientでテストできます。

**注意**

1. 初回の実行には時間がかかります。Hugging face CLIを使用してphi-3モデルをダウンロードすることをお勧めします。
2. Intel NPUの計算能力が限られているため、Phi-3-mini-4k-instructを使用することをお勧めします。
3. INT4変換量子化のためにIntel NPUアクセラレーションを使用していますが、サービスを再実行する場合は、キャッシュとnc_workshopフォルダーを削除する必要があります。

## リソース

1. Promptflowを学ぶ [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)
2. Intel NPUアクセラレーションを学ぶ [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)
3. サンプルコード、[ローカルNPUエージェントのサンプルコードをダウンロード](../../../../../../../code/07.Lab/translations/zh-cn//01/AIPC/local-npu-agent/)
