# **Phi-3.5 패밀리의 새로운 기능**

Phi-3 패밀리를 이미 사용하고 계신가요? 어떤 시나리오에서 사용 중이신가요? 2024년 8월 20일, Microsoft는 다국어, 비전, AI 에이전트 기능이 강화된 새로운 Phi-3.5 패밀리를 출시했습니다. Hugging face의 모델 카드를 통해 더 자세한 소개를 해드리겠습니다.

![PhiFamily](../../../../../translated_images/Phi3getstarted.086dfb90bb69325da6b717586337f2aec5decc241fda85e322eb55c709167f73.ko.png)


## **Phi-3.5-mini-instruct**

Phi-3.5-mini는 Phi-3에서 사용된 데이터셋(합성 데이터 및 필터링된 공개 웹사이트)을 기반으로 구축된 가볍고 최첨단의 오픈 모델입니다. 이 모델은 매우 고품질의, 논리적인 데이터에 중점을 둡니다. Phi-3 모델 패밀리에 속하며 128K 토큰 컨텍스트 길이를 지원합니다. 이 모델은 엄격한 향상 과정을 거쳤으며, 지도 학습 튜닝, 근접 정책 최적화, 직접 선호도 최적화를 통해 정확한 지침 준수와 강력한 안전 조치를 보장합니다.

![benchmark1](../../../../../translated_images/benchmark1.479cb048e7d9239b09e562c410a54f6c9eaf85030af67ac6e7de80a69e4778a5.ko.png)

![benchmark2](../../../../../translated_images/benchmark2.76982d411a07caa3ebd706dd6c0ba98b98a5609de371176a67cd619d70d4e6da.ko.png)

벤치마크 지표를 통해 Phi-3-mini와 비교했을 때 Phi-3.5-mini가 다국어 및 긴 텍스트 콘텐츠 지원이 향상되었음을 알 수 있습니다. 이는 엣지 애플리케이션에서 Phi-3.5 mini의 언어 및 텍스트 기능을 강화하기 위한 것입니다.

우리는 GitHub 모델을 통해 중국어 지식의 능력을 비교할 수 있습니다. "Changsha는 어디에 있나요?"(长沙在哪里?)라는 질문을 할 때, Phi-3-mini-128k-instruct와 Phi-3.5-mini-128k-instruct의 결과를 비교할 수 있습니다.

![Phi3](../../../../../translated_images/gh3.6b1a5c38ed732e40c0effaf4c558badfab0be6148b194aa6bec44adbfb1e4342.ko.png)

![Phi35](../../../../../translated_images/gh35.b0fd2ff379a5f2d995ea1faedd2d7260cfcad7ffbad5a721a8a1b2b3d84028c8.ko.png)

중국어 코퍼스에 대한 데이터 강화가 Phi-3.5-mini가 기본 텍스트 생성 시나리오에서 더 나은 결과를 제공함을 쉽게 알 수 있습니다 (***참고:*** 더 정확한 답변이 필요한 경우, 애플리케이션 시나리오에 따라 세부 튜닝을 권장합니다).

## **Phi-3.5-vision-instruct**

Phi-3.5-vision은 텍스트와 비전 모두에서 매우 고품질의 논리적인 데이터에 중점을 둔 합성 데이터 및 필터링된 공개 웹사이트를 포함한 데이터셋을 기반으로 구축된 가볍고 최첨단의 오픈 멀티모달 모델입니다. 이 모델은 Phi-3 모델 패밀리에 속하며, 멀티모달 버전은 128K 토큰 컨텍스트 길이를 지원합니다. 이 모델은 지도 학습 튜닝과 직접 선호도 최적화를 통해 정확한 지침 준수와 강력한 안전 조치를 보장하기 위해 엄격한 향상 과정을 거쳤습니다.

Vision을 통해 Phi-3.x 패밀리의 눈을 열어 다음과 같은 시나리오를 완성할 수 있었습니다.

1. 메모리/컴퓨팅 제약 환경
2. 지연 시간이 중요한 시나리오
3. 일반적인 이미지 이해
4. 광학 문자 인식
5. 차트 및 테이블 이해
6. 다중 이미지 비교
7. 다중 이미지 또는 비디오 클립 요약

Vision을 통해 Phi 패밀리의 눈을 열어 다음과 같은 시나리오를 완성할 수 있었습니다.

제공된 Hugging face 벤치마크를 사용하여 다양한 비주얼 시나리오에서의 비교를 이해할 수 있습니다.

![benchmark3](../../../../../translated_images/benchmark3.4d9484cc062f0c5076783f3cb33fe533c03995d3a5debc437420e88960032672.ko.png)

Phi-3.5-vision-instruct의 무료 체험을 원하시면 [Nivida NIM](https://build.nvidia.com/microsoft/phi-3_5-vision-instruct)을 사용하여 체험을 완료할 수 있습니다.

![nim](../../../../../translated_images/nim.c985945596d6b2629658087485d16028a3874dcc37329de51b94adf09d0af661.ko.png)

물론 Azure AI Foundry를 통해 배포를 완료할 수도 있습니다.

## **Phi-3.5-MoE-instruct**

Phi-3.5-MoE는 Phi-3에서 사용된 데이터셋(합성 데이터 및 필터링된 공개 문서)을 기반으로 구축된 가볍고 최첨단의 오픈 모델입니다. 이 모델은 다국어를 지원하며 128K 토큰 컨텍스트 길이를 지원합니다. 이 모델은 지도 학습 튜닝, 근접 정책 최적화, 직접 선호도 최적화를 통해 정확한 지침 준수와 강력한 안전 조치를 보장하기 위해 엄격한 향상 과정을 거쳤습니다.

AI 에이전트의 발전과 함께 MoE 모델에 대한 수요는 점차 증가할 것입니다. MoE, 즉 혼합 전문가 모델(Mixed Expert Models)은 여러 전문가 모델을 혼합하여 형성된 새로운 모델입니다. MOE는 큰 문제를 먼저 분할하고 작은 문제를 하나씩 해결한 후 결론을 요약하는 방식입니다. 또한 모델 규모는 모델 성능을 향상시키는 주요 요소 중 하나입니다. 제한된 컴퓨팅 자원으로 더 적은 학습 단계로 더 큰 모델을 학습하는 것이 더 많은 단계를 통해 작은 모델을 학습하는 것보다 종종 더 좋습니다.

Phi-3.5-MoE-Instruct 모델은 Phi-3.5-Vision 및 Phi-3.5-Instruct보다 더 많은 컴퓨팅 파워가 필요합니다. 경험 및 사용을 위해 Azure AI Foundry 및 Nvidia NIM과 같은 클라우드 기반 방법을 사용하는 것이 좋습니다.

![nim2](../../../../../translated_images/nim2.ab50cc468e987efe5e87e8b9b2927f751b6d080c4a146129c2133da94b0f781e.ko.png)


### **🤖 Apple MLX와 함께하는 Phi-3.5 샘플**

| 실험실    | 소개 | 이동 |
| -------- | ------- |  ------- |
| 🚀 Lab-Introduce Phi-3.5 Instruct  | Phi-3.5 Instruct 사용법 배우기 |  [이동](../../../../../code/09.UpdateSamples/Aug/phi3-instruct-demo.ipynb)    |
| 🚀 Lab-Introduce Phi-3.5 Vision (image) | Phi-3.5 Vision을 사용하여 이미지 분석 배우기 |  [이동](../../../../../code/09.UpdateSamples/Aug/phi3-vision-demo.ipynb)    |
| 🚀 Lab-Introduce Phi-3.5 MoE   | Phi-3.5 Vision을 사용하여 이미지 분석 배우기 |  [이동](../../../../../code/09.UpdateSamples/Aug/phi3_moe_demo.ipynb)    |


## **리소스**

1. Hugging face의 Phi 패밀리 [https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3)

2. GitHub 모델에 대한 정보 [https://gh.io/models](https://gh.io/models)

3. Azure AI Foundry에 대한 정보 [https://ai.azure.com/](https://ai.azure.com/)

4. Nividia NIM에 대한 정보 [https://build.nvidia.com/explore/discover](https://build.nvidia.com/explore/discover)

**면책 조항**:
이 문서는 기계 기반 AI 번역 서비스를 사용하여 번역되었습니다. 정확성을 위해 노력하고 있지만 자동 번역에는 오류나 부정확성이 있을 수 있습니다. 원어로 작성된 원본 문서를 권위 있는 출처로 간주해야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 오역에 대해 당사는 책임을 지지 않습니다.