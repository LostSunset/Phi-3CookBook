# **Intel OpenVINO를 사용한 Phi-3.5 양자화**

Intel은 많은 사용자를 보유한 전통적인 CPU 제조업체입니다. 기계 학습과 딥러닝의 부상과 함께, Intel도 AI 가속 경쟁에 합류했습니다. 모델 추론을 위해 Intel은 GPU와 CPU뿐만 아니라 NPU도 사용합니다.

우리는 Phi-3.x Family를 엔드 사이드에 배포하여 AI PC와 Copilot PC의 가장 중요한 부분이 되기를 희망합니다. 엔드 사이드에서 모델을 로딩하는 것은 다양한 하드웨어 제조업체의 협력이 필요합니다. 이 장에서는 주로 Intel OpenVINO를 양자화 모델로 사용하는 응용 시나리오에 대해 설명합니다.


## **OpenVINO란?**

OpenVINO는 클라우드에서 엣지까지 딥러닝 모델을 최적화하고 배포하기 위한 오픈 소스 툴킷입니다. PyTorch, TensorFlow, ONNX 등 인기 있는 프레임워크의 모델을 사용하여 생성 AI, 비디오, 오디오, 언어 등 다양한 사용 사례에서 딥러닝 추론을 가속화합니다. 모델을 변환하고 최적화하여 Intel® 하드웨어와 환경에서 온프레미스 및 온디바이스, 브라우저 또는 클라우드에서 배포할 수 있습니다.

이제 OpenVINO를 사용하면 Intel 하드웨어에서 GenAI 모델을 빠르게 양자화하고 모델 참조를 가속화할 수 있습니다.

이제 OpenVINO는 Phi-3.5-Vision 및 Phi-3.5 Instruct의 양자화 변환을 지원합니다.

### **환경 설정**

다음 환경 종속성이 설치되어 있는지 확인하세요. 이것은 requirement.txt입니다.

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **OpenVINO를 사용하여 Phi-3.5-Instruct 양자화하기**

터미널에서 이 스크립트를 실행하세요.

```bash

export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}

```

### **OpenVINO를 사용하여 Phi-3.5-Vision 양자화하기**

Python 또는 Jupyter Lab에서 이 스크립트를 실행하세요.

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)

model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **🤖 Intel OpenVINO와 함께하는 Phi-3.5 샘플**

| 실험실    | 소개 | 이동 |
| -------- | ------- |  ------- |
| 🚀 Lab-Introduce Phi-3.5 Instruct  | AI PC에서 Phi-3.5 Instruct를 사용하는 방법을 배우세요    |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| 🚀 Lab-Introduce Phi-3.5 Vision (이미지) | AI PC에서 Phi-3.5 Vision을 사용하여 이미지를 분석하는 방법을 배우세요      |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| 🚀 Lab-Introduce Phi-3.5 Vision (비디오)   | AI PC에서 Phi-3.5 Vision을 사용하여 비디오를 분석하는 방법을 배우세요    |  [Go](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |


## **리소스**

1. Intel OpenVINO에 대해 더 알아보기 [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Intel OpenVINO GitHub Repo [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

면책 조항: 이 번역은 AI 모델에 의해 원본에서 번역된 것이며 완벽하지 않을 수 있습니다. 
출력을 검토하고 필요한 수정 사항을 반영해 주시기 바랍니다.