# **Quantification de Phi-3.5 avec Intel OpenVINO**

Intel est le fabricant de CPU le plus traditionnel avec de nombreux utilisateurs. Avec l'essor de l'apprentissage automatique et de l'apprentissage profond, Intel a Ã©galement rejoint la compÃ©tition pour l'accÃ©lÃ©ration de l'IA. Pour l'infÃ©rence de modÃ¨le, Intel utilise non seulement des GPU et des CPU, mais aussi des NPU.

Nous espÃ©rons dÃ©ployer la famille Phi-3.x du cÃ´tÃ© utilisateur, en espÃ©rant devenir la partie la plus importante des PC IA et des PC Copilot. Le chargement du modÃ¨le cÃ´tÃ© utilisateur dÃ©pend de la coopÃ©ration de diffÃ©rents fabricants de matÃ©riel. Ce chapitre se concentre principalement sur le scÃ©nario d'application d'Intel OpenVINO en tant que modÃ¨le quantitatif.

## **Qu'est-ce qu'OpenVINO**

OpenVINO est une boÃ®te Ã  outils open-source pour optimiser et dÃ©ployer des modÃ¨les d'apprentissage profond du cloud Ã  la pÃ©riphÃ©rie. Il accÃ©lÃ¨re l'infÃ©rence de l'apprentissage profond dans divers cas d'utilisation, tels que l'IA gÃ©nÃ©rative, la vidÃ©o, l'audio et le langage avec des modÃ¨les issus de frameworks populaires comme PyTorch, TensorFlow, ONNX, et plus encore. Convertissez et optimisez les modÃ¨les, et dÃ©ployez-les sur un mÃ©lange de matÃ©riel et d'environnements IntelÂ®, sur site et sur appareil, dans le navigateur ou dans le cloud.

Avec OpenVINO, vous pouvez dÃ©sormais quantifier rapidement le modÃ¨le GenAI sur du matÃ©riel Intel et accÃ©lÃ©rer la rÃ©fÃ©rence du modÃ¨le.

OpenVINO prend dÃ©sormais en charge la conversion de quantification de Phi-3.5-Vision et Phi-3.5 Instruct.

### **Configuration de l'environnement**

Veuillez vous assurer que les dÃ©pendances environnementales suivantes sont installÃ©es, ceci est le requirement.txt

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Quantification de Phi-3.5-Instruct avec OpenVINO**

Dans le Terminal, veuillez exÃ©cuter ce script

```bash

export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}

```

### **Quantification de Phi-3.5-Vision avec OpenVINO**

Veuillez exÃ©cuter ce script en Python ou Jupyter lab

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)

if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)

model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **ðŸ¤– Exemples pour Phi-3.5 avec Intel OpenVINO**

| Labs    | Introduction | Aller |
| -------- | ------- |  ------- |
| ðŸš€ Lab-Introduction Phi-3.5 Instruct  | Apprenez Ã  utiliser Phi-3.5 Instruct dans votre PC IA    |  [Aller](../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| ðŸš€ Lab-Introduction Phi-3.5 Vision (image) | Apprenez Ã  utiliser Phi-3.5 Vision pour analyser une image dans votre PC IA      |  [Aller](../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| ðŸš€ Lab-Introduction Phi-3.5 Vision (vidÃ©o)   | Apprenez Ã  utiliser Phi-3.5 Vision pour analyser une vidÃ©o dans votre PC IA    |  [Aller](../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **Ressources**

1. En savoir plus sur Intel OpenVINO [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. RÃ©pertoire GitHub d'Intel OpenVINO [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

Avertissement : La traduction a Ã©tÃ© effectuÃ©e Ã  partir de son original par un modÃ¨le d'IA et peut ne pas Ãªtre parfaite. 
Veuillez examiner le rÃ©sultat et apporter les corrections nÃ©cessaires.