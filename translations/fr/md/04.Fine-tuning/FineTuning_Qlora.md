**Affiner Phi-3 avec QLoRA**

Affiner le modèle de langage Phi-3 Mini de Microsoft en utilisant [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora).

QLoRA aidera à améliorer la compréhension conversationnelle et la génération de réponses.

Pour charger des modèles en 4bits avec transformers et bitsandbytes, vous devez installer accelerate et transformers depuis la source et vous assurer que vous avez la dernière version de la bibliothèque bitsandbytes.

**Exemples**
- [En savoir plus avec ce notebook d'exemple](../../../../code/04.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Exemple de script d'affinage en Python](../../../../code/04.Finetuning/FineTrainingScript.py)
- [Exemple d'affinage sur Hugging Face Hub avec LORA](../../../../code/04.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Exemple d'affinage sur Hugging Face Hub avec QLORA](../../../../code/04.Finetuning/Phi-3-finetune-qlora-python.ipynb)

Avertissement : La traduction a été réalisée à partir de l'original par un modèle d'IA et peut ne pas être parfaite. Veuillez examiner le résultat et apporter les corrections nécessaires.